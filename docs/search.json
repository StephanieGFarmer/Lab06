[
  {
    "objectID": "lab06.html",
    "href": "lab06.html",
    "title": "lab06",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.2.1     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n# Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# where we want to download the data ...\nlocal_files   &lt;- glue('data/camels_{types}.txt')\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n# Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE)\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')"
  },
  {
    "objectID": "lab06.html#question-1",
    "href": "lab06.html#question-1",
    "title": "lab06",
    "section": "Question 1:",
    "text": "Question 1:\n\nzero_q_freq represents the frequency of days with Q=0 mm/day"
  },
  {
    "objectID": "lab06.html#question-2",
    "href": "lab06.html#question-2",
    "title": "lab06",
    "section": "Question 2:",
    "text": "Question 2:\n\nlibrary(ggthemes)\n\n\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map()"
  },
  {
    "objectID": "lab06.html#model-preparation",
    "href": "lab06.html#model-preparation",
    "title": "lab06",
    "section": "model preparation:",
    "text": "model preparation:\n\ncamels |&gt; \n  select(aridity, p_mean, q_mean) |&gt; \n  drop_na() |&gt; \n  cor()\n\n           aridity     p_mean     q_mean\naridity  1.0000000 -0.7550090 -0.5817771\np_mean  -0.7550090  1.0000000  0.8865757\nq_mean  -0.5817771  0.8865757  1.0000000\n\n\n\n# Create a scatter plot of aridity vs rainfall\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  # Add points colored by mean flow\n  geom_point(aes(color = q_mean)) +\n  # Add a linear regression line\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  # Apply the viridis color scale\n  scale_color_viridis_c() +\n  # Add a title, axis labels, and theme (w/ legend on the bottom)\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  # Apply log transformations to the x and y axes\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  # Apply a log transformation to the color scale\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        # Expand the legend width ...\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\n# Bad form to perform simple transformations on the outcome variable within a \n# recipe. So, we'll do it here.\ncamels &lt;- camels |&gt; \n  mutate(logQmean = log(q_mean))\n\n# Generate the split\ncamels_split &lt;- initial_split(camels, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\n# Create a recipe to preprocess the data\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  # Log transform the predictor variables (aridity and p_mean)\n  step_log(all_predictors()) %&gt;%\n  # Add an interaction term between aridity and p_mean\n  step_interact(terms = ~ aridity:p_mean) |&gt; \n  # Drop any rows with missing values in the pred\n  step_naomit(all_predictors(), all_outcomes())\n\n\n# Prepare the data\nbaked_data &lt;- prep(rec, camels_train) |&gt; \n  bake(new_data = NULL)\n\n# Interaction with lm\n#  Base lm sets interaction terms with the * symbol\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\ntest_data &lt;-  bake(prep(rec), new_data = camels_test)\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\nggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +\n  # Apply a gradient color scale\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\n\n# Define model\nlm_model &lt;- linear_reg() %&gt;%\n  # define the engine\n  set_engine(\"lm\") %&gt;%\n  # define the mode\n  set_mode(\"regression\")\n\n# Instantiate a workflow ...\nlm_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(lm_model) %&gt;%\n  # Fit the model to the training data\n  fit(data = camels_train) \n\n# Extract the model coefficients from the workflow\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\n\n# From the base implementation\nsummary(lm_base)$coefficients\n\n                 Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)    -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity        -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean          1.4843771 0.15511117   9.569762 4.022500e-20\naridity:p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\n\n#\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\ndim(lm_data)\n\n[1] 135  61\n\n\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\nggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nlibrary(baguette)\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(rf_model) %&gt;%\n  # Fit the model\n  fit(data = camels_train) \n\n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 135  60\n\n\n\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.587\n2 rsq     standard       0.741\n3 mae     standard       0.363\n\n\n\nggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.563  0.0247    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.771  0.0259    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     2"
  },
  {
    "objectID": "lab06.html#i-think-i-would-choose-the-nnet-regression-model-because-it-showed-the-highest-ranking.",
    "href": "lab06.html#i-think-i-would-choose-the-nnet-regression-model-because-it-showed-the-highest-ranking.",
    "title": "lab06",
    "section": "I think I would choose the nnet regression model because it showed the highest ranking.",
    "text": "I think I would choose the nnet regression model because it showed the highest ranking."
  },
  {
    "objectID": "lab06.html#evaluation",
    "href": "lab06.html#evaluation",
    "title": "lab06",
    "section": "Evaluation:",
    "text": "Evaluation:\n\nThe random forest model is ranked the highest both in workflow and in the rank_results.\n\nrf_wf2 &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(rf_model2) %&gt;%\n  fit(data = camels_train2)\n\nrf_wf2 &lt;- augment(rf_wf2, new_data = camels_test2)\ndim(rf_wf2)\n\n[1] 168  60\n\n\n\nggplot(rf_wf2, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()"
  },
  {
    "objectID": "lab06.html#describing-the-results",
    "href": "lab06.html#describing-the-results",
    "title": "lab06",
    "section": "Describing the results:",
    "text": "Describing the results:\n\nI think the results correlate with the given comparisons and it seems close to the predictions."
  },
  {
    "objectID": "hyperparameter-tuning.html",
    "href": "hyperparameter-tuning.html",
    "title": "hyperparameter-tuning",
    "section": "",
    "text": "library(ggthemes)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.2.1     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip) \n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\nlibrary(dplyr)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(baguette)\nlibrary(workflowsets)\n\n\n# root  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n# download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n#               'data/camels_attributes_v2.0.pdf')\n# \ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n# remote_files  &lt;- glue('{root}/camels_{types}.txt')\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n# walk2(remote_files, local_files, download.file, quiet = TRUE)\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE)\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')"
  },
  {
    "objectID": "hyperparameter-tuning.html#data-import-tidy-transform",
    "href": "hyperparameter-tuning.html#data-import-tidy-transform",
    "title": "hyperparameter-tuning",
    "section": "",
    "text": "library(ggthemes)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.2.1     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip) \n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\nlibrary(dplyr)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(baguette)\nlibrary(workflowsets)\n\n\n# root  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n# download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n#               'data/camels_attributes_v2.0.pdf')\n# \ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n# remote_files  &lt;- glue('{root}/camels_{types}.txt')\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n# walk2(remote_files, local_files, download.file, quiet = TRUE)\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE)\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')"
  },
  {
    "objectID": "hyperparameter-tuning.html#data-cleaning",
    "href": "hyperparameter-tuning.html#data-cleaning",
    "title": "hyperparameter-tuning",
    "section": "Data cleaning:",
    "text": "Data cleaning:\n\ncamels_clean &lt;- camels %&gt;%\n  mutate(\n    #gauge_id = as.character(gauge_id),\n    high_prec_timing = as.character(high_prec_timing),\n    low_prec_timing = as.character(low_prec_timing),\n    dom_land_cover  = as.character(dom_land_cover),\n    geol_1st_class  = as.character(geol_1st_class),\n    geol_2nd_class  = as.character(geol_2nd_class)) %&gt;% \n  mutate(across(where(is.numeric), ~ifelse(is.na(.), median(., na.rm = TRUE), .))) %&gt;%\n  mutate(q_mean = log(q_mean)) %&gt;% \n  select(aridity, high_prec_freq, low_prec_freq, gauge_lat, gauge_lon, q_mean) %&gt;% \n  drop_na()\n\nnames(camels_clean)\n\n[1] \"aridity\"        \"high_prec_freq\" \"low_prec_freq\"  \"gauge_lat\"     \n[5] \"gauge_lon\"      \"q_mean\""
  },
  {
    "objectID": "hyperparameter-tuning.html#data-splitting",
    "href": "hyperparameter-tuning.html#data-splitting",
    "title": "hyperparameter-tuning",
    "section": "Data splitting:",
    "text": "Data splitting:\n\nset.seed(123)\ndata_split &lt;- initial_split(camels_clean, prop = 0.8)\ntrain_data &lt;- training(data_split)\ntest_data &lt;- testing(data_split)\n\nfolds &lt;- vfold_cv(train_data, v = 10)"
  },
  {
    "objectID": "hyperparameter-tuning.html#feature-engineering",
    "href": "hyperparameter-tuning.html#feature-engineering",
    "title": "hyperparameter-tuning",
    "section": "Feature engineering:",
    "text": "Feature engineering:\n\nrec &lt;- recipe(q_mean ~ ., data = train_data) %&gt;%\n  step_rm(gauge_lat, gauge_lon) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_impute_median(all_numeric_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors())"
  },
  {
    "objectID": "hyperparameter-tuning.html#resampling-and-model-testing",
    "href": "hyperparameter-tuning.html#resampling-and-model-testing",
    "title": "hyperparameter-tuning",
    "section": "Resampling and Model testing:",
    "text": "Resampling and Model testing:\n\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nnn_model &lt;- bag_mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model, nn_model)) %&gt;%\n  workflow_map(resamples = folds, \n               metrics = metric_set(rmse, rsq),\n               control = control_resamples(save_pred = TRUE)) \n\nautoplot(wf)"
  },
  {
    "objectID": "hyperparameter-tuning.html#question-4-describe-the-model-you-selected.-what-is-the-model-type-engine-and-mode.-why-do-you-think-it-is-performing-well-for-this-problem",
    "href": "hyperparameter-tuning.html#question-4-describe-the-model-you-selected.-what-is-the-model-type-engine-and-mode.-why-do-you-think-it-is-performing-well-for-this-problem",
    "title": "hyperparameter-tuning",
    "section": "Question 4: Describe the model you selected. What is the model type, engine, and mode. Why do you think it is performing well for this problem?",
    "text": "Question 4: Describe the model you selected. What is the model type, engine, and mode. Why do you think it is performing well for this problem?\n\nThe model selected is a Random Forest model. It uses the ranger engine anad operares in regression mode. The model type is an ensemble learning method that builds multiple decision trees and combines their predictions, which typically improves accuracy and robustness. The model performs well with this lab because it handles non-linear relationships and interactions between predictors effectively. It is also resistant to overfitting, especially when combined with cross-validation, and performs well with correlated or partially informative features."
  },
  {
    "objectID": "hyperparameter-tuning.html#model-tuning",
    "href": "hyperparameter-tuning.html#model-tuning",
    "title": "hyperparameter-tuning",
    "section": "Model Tuning:",
    "text": "Model Tuning:\n\nnn_tune &lt;- bag_mlp(\n  hidden_units = tune(), \n  penalty = tune(), \n  epochs = tune()\n) %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nwf_tune &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(nn_tune)\n\ndials &lt;- extract_parameter_set_dials(wf_tune)\ndials$object\n\n[[1]]\n\n\n# Hidden Units (quantitative)\n\n\nRange: [1, 10]\n\n\n\n[[2]]\n\n\nAmount of Regularization (quantitative)\n\n\nTransformer: log-10 [1e-100, Inf]\n\n\nRange (transformed scale): [-10, 0]\n\n\n\n[[3]]\n\n\n# Epochs (quantitative)\n\n\nRange: [10, 1000]\n\nmy.grid &lt;- grid_latin_hypercube(\n  dials,\n  size = 25\n)\n\nWarning: `grid_latin_hypercube()` was deprecated in dials 1.3.0.\nℹ Please use `grid_space_filling()` instead.\n\nmodel_params &lt;-  tune_grid(\n    wf_tune,\n    resamples = folds,\n    grid = my.grid,\n    metrics = metric_set(rmse, rsq, mae),\n    control = control_grid(save_pred = TRUE)\n  )\n\nautoplot(model_params)\n\n\n\n\n\n\n\ncollect_metrics(model_params) %&gt;%\n  arrange(mean)\n\n# A tibble: 75 × 9\n   hidden_units  penalty epochs .metric .estimator  mean     n std_err .config  \n          &lt;int&gt;    &lt;dbl&gt;  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;    \n 1            7 1.17e- 4    700 mae     standard   0.299    10  0.0170 Preproce…\n 2            8 1.35e- 2    898 mae     standard   0.300    10  0.0171 Preproce…\n 3            8 8.95e- 4    794 mae     standard   0.301    10  0.0164 Preproce…\n 4            6 3.69e- 5    187 mae     standard   0.302    10  0.0179 Preproce…\n 5            9 2.29e- 8    225 mae     standard   0.304    10  0.0176 Preproce…\n 6            5 2.48e- 3    594 mae     standard   0.306    10  0.0175 Preproce…\n 7            9 5.54e- 9    132 mae     standard   0.307    10  0.0178 Preproce…\n 8            7 3.00e-10    308 mae     standard   0.313    10  0.0183 Preproce…\n 9            5 5.22e- 3    876 mae     standard   0.313    10  0.0185 Preproce…\n10            6 1.18e-10     78 mae     standard   0.315    10  0.0165 Preproce…\n# ℹ 65 more rows\n\nshow_best(model_params, metric = \"mae\")\n\n# A tibble: 5 × 9\n  hidden_units     penalty epochs .metric .estimator  mean     n std_err .config\n         &lt;int&gt;       &lt;dbl&gt;  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n1            7     1.17e-4    700 mae     standard   0.299    10  0.0170 Prepro…\n2            8     1.35e-2    898 mae     standard   0.300    10  0.0171 Prepro…\n3            8     8.95e-4    794 mae     standard   0.301    10  0.0164 Prepro…\n4            6     3.69e-5    187 mae     standard   0.302    10  0.0179 Prepro…\n5            9     2.29e-8    225 mae     standard   0.304    10  0.0176 Prepro…\n\nhp_best &lt;- select_best(model_params, metric = \"mae\")"
  },
  {
    "objectID": "hyperparameter-tuning.html#question-5-please-interpret-the-results-of-the-first-row-of-show_best.-what-do-you-see-what-hyperparameter-set-is-best-for-this-model-based-on-mae",
    "href": "hyperparameter-tuning.html#question-5-please-interpret-the-results-of-the-first-row-of-show_best.-what-do-you-see-what-hyperparameter-set-is-best-for-this-model-based-on-mae",
    "title": "hyperparameter-tuning",
    "section": "Question 5: Please interpret the results of the first row of show_best(). What do you see? What hyperparameter set is best for this model, based on MAE?",
    "text": "Question 5: Please interpret the results of the first row of show_best(). What do you see? What hyperparameter set is best for this model, based on MAE?"
  },
  {
    "objectID": "hyperparameter-tuning.html#use-the-collect_metrics-function-to-check-the-skill-of-the-tuned-model.-describe-what-you-see-remember-dplyr-functions-like-arrange-slice_-and-filter-will-work-on-this-tibble.",
    "href": "hyperparameter-tuning.html#use-the-collect_metrics-function-to-check-the-skill-of-the-tuned-model.-describe-what-you-see-remember-dplyr-functions-like-arrange-slice_-and-filter-will-work-on-this-tibble.",
    "title": "hyperparameter-tuning",
    "section": "Use the collect_metrics() function to check the skill of the tuned model. Describe what you see, remember dplyr functions like arrange, slice_*, and filter will work on this tibble.",
    "text": "Use the collect_metrics() function to check the skill of the tuned model. Describe what you see, remember dplyr functions like arrange, slice_*, and filter will work on this tibble.\n\nThe show_best() function filters to only the “mae” metric and shows the best parameter combinations. The mean MAE of 2.45 suggests the model has a prediction eroor of about 0.245 log units on q_mean, making it a relatively small error and implies good accuracy.\n\n\nThe collect_metrics() results show that the best-performing model, based on MAE, uses 7 hidden units. The results indicate both strong predictive skill and stable performance across resamples."
  },
  {
    "objectID": "hyperparameter-tuning.html#finalize-the-model",
    "href": "hyperparameter-tuning.html#finalize-the-model",
    "title": "hyperparameter-tuning",
    "section": "Finalize the model:",
    "text": "Finalize the model:\n\nfinal_wf &lt;- finalize_workflow(wf_tune, hp_best)\nfinal_fit &lt;- last_fit(final_wf, data_split)\n\nfinal_metrics &lt;- collect_metrics(final_fit)\nfinal_metrics\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.432 Preprocessor1_Model1\n2 rsq     standard       0.859 Preprocessor1_Model1\n\nfinal_preds &lt;- collect_predictions(final_fit)\n\nggplot(final_preds, aes(x = .pred, y = q_mean)) +\n  geom_point(alpha = 0.5) +\n  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  scale_color_viridis_c() +\n  labs(x = \"Predicted log(q_mean)\", y = \"Actual log(q_mean)\",\n       title = \"Model Predictions vs Actual Values\",\n       subtitle = \"Test Set Performance\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "hyperparameter-tuning.html#question-6-interpret-these-results.-how-does-the-final-model-perform-on-the-test-data-is-it-better-or-worse-than-the-training-data-use-your-knowledge-of-the-regression-based-metrics-to-describe-the-results.",
    "href": "hyperparameter-tuning.html#question-6-interpret-these-results.-how-does-the-final-model-perform-on-the-test-data-is-it-better-or-worse-than-the-training-data-use-your-knowledge-of-the-regression-based-metrics-to-describe-the-results.",
    "title": "hyperparameter-tuning",
    "section": "Question 6: Interpret these results. How does the final model perform on the test data? Is it better or worse than the training data? Use your knowledge of the regression based metrics to describe the results.",
    "text": "Question 6: Interpret these results. How does the final model perform on the test data? Is it better or worse than the training data? Use your knowledge of the regression based metrics to describe the results.\n\nThe final tuned model performs well on the data with predictions closely aligning yo actual values across most of the range of log(q_mean). There is some deviation, especially at lower flow values, the overall trend is strong as reflected at the blue regression line. The results indicate good generalization from training to test data."
  },
  {
    "objectID": "hyperparameter-tuning.html#building-a-map",
    "href": "hyperparameter-tuning.html#building-a-map",
    "title": "hyperparameter-tuning",
    "section": "Building a Map:",
    "text": "Building a Map:\n\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(patchwork)\n\nfull_fit &lt;- fit(final_wf, camels_clean)\ncamels_pred &lt;- camels_clean %&gt;%\n  bind_cols(predict(full_fit, new_data = camels_clean)) %&gt;%\n  mutate(residual = q_mean - .pred)\n\ncamels_sf &lt;- st_as_sf(camels_pred, \n                     coords = c(\"gauge_lon\", \"gauge_lat\"),\n                     crs = 4326)\nus_states &lt;- st_as_sf(maps::map(\"state\", plot = FALSE, fill = TRUE))\n\npred_map &lt;- ggplot() +\n  geom_sf(data = us_states, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = camels_sf, aes(color = .pred), size = 2) +\n  scale_color_viridis_c() +\n  labs(title = \"Predicted Mean Streamflow Across US\") +\n  theme_map()\n\nresid_map &lt;- ggplot() +\n  geom_sf(data = us_states, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = camels_sf, aes(color = residual), size = 2) +\n  scale_color_gradient2() +\n  labs(title = \"Model Residuals Across US\") +\n  theme_map()\n\ncombined_map &lt;- pred_map + resid_map \ncombined_map"
  }
]